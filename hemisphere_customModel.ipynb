{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from os import listdir\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import pydicom\n",
    "import math \n",
    "from pathlib import Path\n",
    "import copy\n",
    "import operator\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import csv\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.optimizers import Adam# use ADAM if it doesnt work\n",
    "from tensorflow.keras.optimizers import legacy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import visualkeras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract labels from excel file: ESCAPENA1 data for CIPAC 2022.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('05-Scripts/ESCAPENA1 data for CIPAC 2022.xlsx')\n",
    "values = df.loc[df[\"Recanalized?\"] == \"Yes\", \"siteangside(1=L, 2=R)\"].tolist()\n",
    "\n",
    "vl=values[1:81]\n",
    "\n",
    "labels = [x - 1.0 for x in vl]\n",
    "labels = [int(x) for x in labels]\n",
    "labels=np.array(labels)\n",
    "#print(labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data from folder IM1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files = glob.glob(\"/Shared/CipacProcessing/Projects/RF_ML_ENA1/IM1/*.jpg\")\n",
    "\n",
    "#newL=[s.split('/')[-1] for s in list_files]\n",
    "#print(newL)\n",
    "new_file_list = [file_path for file_path in list_files if file_path.find('Oc') == -1]\n",
    "\n",
    "\n",
    "pixel_data=[]\n",
    "for name in new_file_list:\n",
    "    try:\n",
    "        img = Image.open(name).convert('L')  # Convert image to grayscale\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {name}\")\n",
    "        continue\n",
    "    if img.size == (1024, 1024):\n",
    "        # Apply histogram equalization\n",
    "        img = cv2.equalizeHist(np.array(img))\n",
    "        # Apply gamma correction\n",
    "        img = np.array(255 * (img / 255) ** 0.2, dtype=np.uint8) # PLAY WITH THIS (0.85) - lower is lighter image\n",
    "        pixel_array = np.array(img)\n",
    "        #min-max normalization\n",
    "        min_value = np.min(pixel_array)\n",
    "        max_value = np.max(pixel_array)\n",
    "        pixel_array = (pixel_array - min_value) / (max_value - min_value + 1e-12)        \n",
    "        pixel_data.append(pixel_array.reshape(pixel_array.shape[0], pixel_array.shape[1], 1))\n",
    "\n",
    "pixel_data=np.array(pixel_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train/val/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_patients(subjects, ratios):\n",
    "\n",
    "    number_of_patients = len(subjects)\n",
    "    train_size = int(number_of_patients*ratios[0])\n",
    "    test_size = number_of_patients - train_size\n",
    "\n",
    "    val_size = int(train_size*ratios[1])\n",
    "    train_size -= val_size\n",
    "\n",
    "    return train_size, val_size, test_size\n",
    "ratios = [0.8, 0.2]#train/val\n",
    "train_size, val_size, test_size = split_patients(pixel_data,ratios)\n",
    "pixel_array_train = pixel_data[:train_size]\n",
    "pixel_array_val = pixel_data[train_size:train_size+val_size]\n",
    "pixel_array_test = pixel_data[train_size+val_size:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "labels_train = labels[:train_size]\n",
    "labels_val = labels[train_size:train_size+val_size]\n",
    "labels_test = labels[train_size+val_size:]\n",
    "print(pixel_array_train.shape, labels_train.shape)\n",
    "print(pixel_array_val.shape, labels_val.shape)\n",
    "print(pixel_array_test.shape, labels_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell to print out images to see what they look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(pixel_array_train[12]), np.max(pixel_array_train[12]))\n",
    "print(np.min(pixel_array_train[13]), np.max(pixel_array_train[13]))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(labels_train[22])\n",
    "plt.imshow(pixel_array_train[22], cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(labels_train[23])\n",
    "plt.imshow(pixel_array_train[23], cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation for Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=5,# Rotate image by up to 10 degrees\n",
    "    width_shift_range=0.01,  # Shift image horizontally by up to 5% of the image size\n",
    "    height_shift_range=0.01,  # Shift image vertically by up to 5% of the image size\n",
    "    zoom_range=0.01,  # Zoom in or out by up to 5%\n",
    "    horizontal_flip=False,  \n",
    "    vertical_flip=False,\n",
    "    # fill_mode='nearest',  # Fill missing pixels with the nearest value\n",
    "    # preprocessing_function=preprocess_input  # Preprocess input using ResNet50 preprocessing\n",
    ")\n",
    "\n",
    "# no augmentation for val set\n",
    "datagen_val = ImageDataGenerator()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Model & visualize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (1024, 1024, 1)\n",
    "\n",
    "# model\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "visualkeras.layered_view(model, scale_xy=0.3,legend=True, spacing=30 )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the callbacks\n",
    "earlyStopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='auto')\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.12, patience=7, min_lr=1e-8)\n",
    "\n",
    "model_chck_point_path = \"/Shared/CipacProcessing/Projects/RF_ML_ENA1/my_models/Final_models/mh1.h5\"\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(model_chck_point_path, mode = 'auto', monitor='val_loss',verbose=0, save_best_only=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile\n",
    "opt = legacy.Adam(lr=1e-4) \n",
    "model.compile(optimizer=opt,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model and save best model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train \n",
    "batch_size_ = 52\n",
    "hist = model.fit(datagen.flow(pixel_array_train, labels_train,batch_size=52,shuffle=True), \n",
    "                 epochs=20,verbose=1, batch_size=52, \n",
    "                 validation_data=datagen.flow(pixel_array_val, labels_val, batch_size=12,shuffle=True), \n",
    "                 callbacks=[checkpoint, reduce_lr])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load = keras.models.load_model(model_chck_point_path)\n",
    "test_loss, test_acc = model_load.evaluate(pixel_array_test, labels_test, verbose=0)\n",
    "\n",
    "y_pred = model_load.predict(pixel_array_test)\n",
    "binary_predictions = np.round(y_pred)\n",
    "\n",
    "f1 = f1_score(labels_test, binary_predictions)\n",
    "\n",
    "accuracy = accuracy_score(labels_test, binary_predictions)\n",
    "\n",
    "print(\"score using .evaluate():\",test_acc)\n",
    "print(\"accuracy score:\",accuracy)\n",
    "print(\"f1-score:\",f1)\n",
    "print(\"----------------------------------------------------------------\")\n",
    "report = classification_report(labels_test, binary_predictions)\n",
    "print (report)\n",
    "print(\"----------------------------------------------------------------\")\n",
    "matrix = confusion_matrix(labels_test, binary_predictions)\n",
    "print (matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['left', 'right']\n",
    "\n",
    "cmd = ConfusionMatrixDisplay(matrix, display_labels=class_names)\n",
    "cmd.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,5), dpi=150)\n",
    "plt.grid('on')\n",
    "plt.title('Loss Function')\n",
    "plt.plot(hist.history['loss'], 'b', lw=2, alpha=0.7, label='Training')\n",
    "plt.plot(hist.history['val_loss'], 'r', lw=2, alpha=0.7, label='Val')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot detection tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fpr_fnr_threshold(y_true, y_scores):\n",
    "    thresholds = np.sort(np.unique(y_scores))\n",
    "    fpr = np.zeros_like(thresholds)\n",
    "    fnr = np.zeros_like(thresholds)\n",
    "    \n",
    "    for i, thresh in enumerate(thresholds):\n",
    "        y_pred = (y_scores >= thresh).astype(int)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "        fpr[i] = fp / (fp + tn)\n",
    "        fnr[i] = fn / (fn + tp)\n",
    "\n",
    "    return fpr, fnr, thresholds\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "pixel_array_test = np.array(pixel_array_test)  \n",
    "predictions = model.predict(pixel_array_test)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(labels_test, predictions)\n",
    "\n",
    "interpolate_fpr = np.linspace(0, 1, num=10)\n",
    "interpolate_tpr = np.interp(interpolate_fpr, fpr, tpr)\n",
    "\n",
    "roc_auc = auc(interpolate_fpr, interpolate_tpr)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(interpolate_fpr, interpolate_tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "fpr, fnr, thresholds = fpr_fnr_threshold(labels_test, predictions)\n",
    "\n",
    "interpolated_fpr = np.linspace(0, 1, num=10)\n",
    "interpolated_fnr = np.interp(interpolated_fpr, fpr, fnr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(interpolated_fpr, interpolated_fnr, color='darkorange', lw=2)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('False Negative Rate')\n",
    "plt.title('Detection Error Tradeoff')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pixel_array = np.concatenate((pixel_array_train, pixel_array_val, pixel_array_test), axis=0)\n",
    "full_label_array = np.concatenate((labels_train, labels_val, labels_test), axis=0)\n",
    "print(full_pixel_array.shape,full_label_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_splits = 5\n",
    "pixel_array_splits = np.array_split(full_pixel_array, num_splits)\n",
    "label_array_splits = np.array_split(full_label_array, num_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    #rotation_range=10,  # Rotate image by up to 10 degrees\n",
    "    width_shift_range=0.05,  # Shift image horizontally by up to 5% of the image size\n",
    "    height_shift_range=0.1,  # Shift image vertically by up to 5% of the image size\n",
    "    zoom_range=0.1,  # Zoom in or out by up to 5%\n",
    "    horizontal_flip=False,  # Flip image horizontally\n",
    "    # vertical_flip=True,\n",
    "    # fill_mode='nearest',  # Fill missing pixels with the nearest value\n",
    "    # preprocessing_function=preprocess_input  # Preprocess input using ResNet50 preprocessing\n",
    ")\n",
    "\n",
    "datagen_val = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_splits = 5\n",
    "scores_acc_eval = []\n",
    "scores_acc_acc = []\n",
    "scores_f1 = []\n",
    "classification_reports = []\n",
    "confusion_matrices = []\n",
    "\n",
    "# Change folder name as needed\n",
    "\n",
    "model_folder = \"/Shared/CipacProcessing/Projects/RF_ML_ENA1/my_models/Final_models/\"\n",
    "model_basename = \"mh_cross\"\n",
    "\n",
    "for val_index in range(num_splits):\n",
    "    # select one split as validation set\n",
    "    val_pixel_array = pixel_array_splits[val_index]\n",
    "    val_label_array = label_array_splits[val_index]\n",
    "\n",
    "    # combine remaining splits into training set\n",
    "    train_pixel_array = np.concatenate(\n",
    "        [split for i, split in enumerate(pixel_array_splits) if i != val_index],\n",
    "        axis=0\n",
    "    )\n",
    "    train_label_array = np.concatenate(\n",
    "        [split for i, split in enumerate(label_array_splits) if i != val_index],\n",
    "        axis=0\n",
    "    )\n",
    "\n",
    "    # Shuffle training set and corresponding indices\n",
    "    train_shuffle_indices = np.random.permutation(len(train_pixel_array))\n",
    "    train_pixel_array = train_pixel_array[train_shuffle_indices]\n",
    "    train_label_array = train_label_array[train_shuffle_indices]\n",
    "\n",
    "    # Shuffle validation set and corresponding indices\n",
    "    val_shuffle_indices = np.random.permutation(len(val_pixel_array))\n",
    "    val_pixel_array = val_pixel_array[val_shuffle_indices]\n",
    "    val_label_array = val_label_array[val_shuffle_indices]\n",
    "    # train and evaluate model on this split\n",
    "\n",
    "    # Define the data generators for this fold\n",
    "    train_datagen = datagen.flow(train_pixel_array, train_label_array, batch_size=32, shuffle=True)\n",
    "    val_datagen = datagen_val.flow(val_pixel_array, val_label_array, batch_size=32)\n",
    "    \n",
    "    opt = legacy.Adam(lr=1e-4)\n",
    "\n",
    "    # Define the callbacks\n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=6, min_lr=1e-8)\n",
    "    # model_chck_point_path = \"/Shared/CipacProcessing/Projects/RF_ML_ENA1/my_models/mymodelfin5.h5\"\n",
    "    model_chck_point_path = f\"{model_folder}{model_basename}_split{val_index+1}.h5\"\n",
    "    print(model_chck_point_path)\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(model_chck_point_path, mode = 'auto', monitor='val_loss',verbose=0, save_best_only=True)\n",
    "\n",
    "    # Define and compile the model\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "    #load model first\n",
    "\n",
    "    # Train the model for this fold\n",
    "    hist = model.fit(train_datagen, \n",
    "                    steps_per_epoch=len(train_datagen),\n",
    "                    epochs=20, \n",
    "                    verbose=1, \n",
    "                    validation_data=val_datagen,\n",
    "                    callbacks=[checkpoint, reduce_lr])\n",
    "\n",
    "\n",
    "    #load model first\n",
    "    model = keras.models.load_model(model_chck_point_path)\n",
    "\n",
    "\n",
    "    # Evaluate the model on the test set for this fold and store the accuracy score\n",
    "    test_loss, test_acc = model.evaluate(val_pixel_array, val_label_array, verbose=0)\n",
    "    scores_acc_eval.append(test_acc)\n",
    "\n",
    "    y_pred = model.predict(val_pixel_array)\n",
    "    binary_predictions = np.round(y_pred)\n",
    "\n",
    "    f1 = f1_score(val_label_array, binary_predictions)\n",
    "    scores_f1.append(f1)\n",
    "\n",
    "    accuracy = accuracy_score(val_label_array, binary_predictions)\n",
    "    scores_acc_acc.append(accuracy)\n",
    "\n",
    "    report = classification_report(val_label_array, binary_predictions)\n",
    "    classification_reports.append(report)\n",
    "\n",
    "    matrix = confusion_matrix(val_label_array, binary_predictions)\n",
    "    confusion_matrices.append(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"scores acc eval:\",scores_acc_eval)\n",
    "print(\"accuracy scores:\",scores_acc_acc)\n",
    "print(\"f1-scores:\",scores_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"------------------------ RUN 1 (fold 1) ------------------------\")\n",
    "print(classification_reports[0])\n",
    "print(\"------------------------ RUN 2 (fold 2) ------------------------\")\n",
    "print(classification_reports[1])\n",
    "print(\"------------------------ RUN 3 (fold 3) ------------------------\")\n",
    "print(classification_reports[2])\n",
    "print(\"------------------------ RUN 4 (fold 4) ------------------------\")\n",
    "print(classification_reports[3])\n",
    "print(\"------------------------ RUN 5 (fold 5) ------------------------\")\n",
    "print(classification_reports[4])\n",
    "\n",
    "# classification_reports\n",
    "# confusion_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['occluded', 'recanalized']\n",
    "\n",
    "print(\"------------------------ RUN 1 (fold 1) ------------------------\")\n",
    "cmd = ConfusionMatrixDisplay(confusion_matrices[0], display_labels=class_names)\n",
    "cmd.plot()\n",
    "print(\"------------------------ RUN 2 (fold 2) ------------------------\")\n",
    "cmd = ConfusionMatrixDisplay(confusion_matrices[1], display_labels=class_names)\n",
    "cmd.plot()\n",
    "print(\"------------------------ RUN 3 (fold 3) ------------------------\")\n",
    "cmd = ConfusionMatrixDisplay(confusion_matrices[2], display_labels=class_names)\n",
    "cmd.plot()\n",
    "print(\"------------------------ RUN 4 (fold 4) ------------------------\")\n",
    "cmd = ConfusionMatrixDisplay(confusion_matrices[3], display_labels=class_names)\n",
    "cmd.plot()\n",
    "print(\"------------------------ RUN 5 (fold 5) ------------------------\")\n",
    "cmd = ConfusionMatrixDisplay(confusion_matrices[4], display_labels=class_names)\n",
    "cmd.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,5), dpi=150)\n",
    "plt.grid('on')\n",
    "plt.title('Loss Function')\n",
    "plt.plot(hist.history['loss'], 'b', lw=2, alpha=0.7, label='Training')\n",
    "plt.plot(hist.history['val_loss'], 'r', lw=2, alpha=0.7, label='Val')\n",
    "plt.legend(loc=\"upper right\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

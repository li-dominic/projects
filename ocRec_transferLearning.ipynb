{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from os import listdir\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import pydicom\n",
    "import math \n",
    "from pathlib import Path\n",
    "import copy\n",
    "import operator\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.optimizers import Adam# use ADAM if it doesnt work\n",
    "from tensorflow.keras.optimizers import legacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_patients(subjects, ratios):\n",
    "\n",
    "    number_of_patients = len(subjects)\n",
    "    train_size = int(number_of_patients*ratios[0])\n",
    "    test_size = number_of_patients - train_size\n",
    "\n",
    "    val_size = int(train_size*ratios[1])\n",
    "    train_size -= val_size\n",
    "\n",
    "    return train_size, val_size, test_size\n",
    "\n",
    "\n",
    "def process_subjects(list_of_names, table):\n",
    "    pixel_data = []\n",
    "    labels = []\n",
    "\n",
    "    for name in list_of_names:\n",
    "        matching_files = table.loc[table['name'] == name]\n",
    "\n",
    "        for _, row in matching_files.iterrows():\n",
    "            filename = row['filename']\n",
    "            label = row['label']\n",
    "            try:\n",
    "                img = Image.open(\"/Shared/CipacProcessing/Projects/RF_ML_ENA1/IM1/\"+f\"{filename}\").convert('L')  # Convert image to grayscale\n",
    "            except FileNotFoundError:\n",
    "                print(f\"File not found: {filename}\")\n",
    "                continue\n",
    "            \n",
    "            if img.size == (1024, 1024):\n",
    "                pixel_array = np.array(img)\n",
    "                #min-max normalization\n",
    "                min_value = np.min(pixel_array)\n",
    "                max_value = np.max(pixel_array)\n",
    "                pixel_array = (pixel_array - min_value) / (max_value - min_value + 1e-12)\n",
    "                \n",
    "                pixel_data.append(pixel_array.reshape(pixel_array.shape[0], pixel_array.shape[1], 1))\n",
    "                labels.append(label)\n",
    "\n",
    "    labels_array = np.array([0 if label.lower() == \"oc\" else 1 for label in labels])\n",
    "    pixel_array = np.stack(pixel_data, axis=0)  # Stack arrays along a new dimension\n",
    "    \n",
    "    return pixel_array, labels_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files = glob.glob(\"/Shared/CipacProcessing/Projects/RF_ML_ENA1/IM1/*.jpg\")\n",
    "print(len(list_files))\n",
    "table_metadata = pd.read_csv(\"/Shared/CipacProcessing/Projects/RF_ML_ENA1/table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = set()\n",
    "\n",
    "for s in table_metadata[\"name\"]:\n",
    "    subjects.add(s)\n",
    "\n",
    "print(\"Number of patients:\", len(subjects))\n",
    "\n",
    "np.random.seed(2)\n",
    "subject_list = list(subjects)\n",
    "np.random.shuffle(subject_list)\n",
    "\n",
    "ratios = [0.8, 0.2]#train/val\n",
    "train_size, val_size, test_size = split_patients(subjects, ratios)\n",
    "\n",
    "subject_train_set = subject_list[:train_size]\n",
    "subject_val_set = subject_list[train_size:train_size+val_size]\n",
    "subject_test_set = subject_list[train_size+val_size:]\n",
    "\n",
    "print(\"Train size:\", train_size)\n",
    "print(\"Val size:\", val_size)\n",
    "print(\"Test size:\", test_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_array_train, labels_train = process_subjects(subject_train_set, table_metadata)\n",
    "pixel_array_val, labels_val = process_subjects(subject_val_set, table_metadata)\n",
    "pixel_array_test, labels_test = process_subjects(subject_test_set, table_metadata)\n",
    "\n",
    "zeroList = []\n",
    "oneList = []\n",
    "for i in range(len(pixel_array_train)):\n",
    "    if (labels_train[i] == 0):\n",
    "        zeroList.append(pixel_array_train[i])\n",
    "    else:\n",
    "        oneList.append(pixel_array_train[i])\n",
    "\n",
    "zeroList = np.array(zeroList)\n",
    "oneList = np.array(oneList)\n",
    "oneList = oneList.reshape(oneList.shape[0],oneList.shape[1],oneList.shape[2],1)\n",
    "zeroList = zeroList.reshape(zeroList.shape[0],zeroList.shape[1],zeroList.shape[2],1)\n",
    "\n",
    "images0 = zeroList\n",
    "images1 = oneList\n",
    "\n",
    "datagen_train = ImageDataGenerator(\n",
    "    rotation_range=5,  # Small rotations\n",
    "    width_shift_range=0.1,  # Small horizontal shifts\n",
    "    height_shift_range=0.1,  # Small vertical shifts\n",
    "    zoom_range=0.1,  # Slight zoom in and out\n",
    "    shear_range=0.1,\n",
    "    #horizontal_flip=True\n",
    "    # vertical_flip=False, \n",
    "    fill_mode='nearest'  # Fill missing pixels with the nearest value\n",
    "    #preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "it0 = datagen_train.flow(images0, batch_size = 1)\n",
    "it1 = datagen_train.flow(images1, batch_size = 1)\n",
    "\n",
    "augmented0_train = []\n",
    "augmented1_train = []\n",
    "\n",
    "for i in range(len(images0)):\n",
    "    for j in range(10):\n",
    "        batch = it0.next()\n",
    "        image0 = batch[0]\n",
    "        augmented0_train.append(image0)\n",
    "\n",
    "for i in range(len(images1)):\n",
    "    for j in range(10):\n",
    "        batch = it1.next()\n",
    "        image1 = batch[0]\n",
    "        augmented1_train.append(image1)\n",
    "\n",
    "augmented0_train = np.array(augmented0_train)\n",
    "augmented1_train = np.array(augmented1_train)\n",
    "\n",
    "augmented0 = np.concatenate([augmented0_train, images0], axis=0)\n",
    "augmented1 = np.concatenate([augmented1_train, images1], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "print(augmented0.shape)\n",
    "print(augmented1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_train = np.concatenate((augmented1, augmented0), axis=0)\n",
    "newLabels = np.concatenate((np.ones(572), np.zeros(572)))\n",
    "\n",
    "indices = np.arange(len(concatenated_train))\n",
    "\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "pixel_array_train = concatenated_train[indices]\n",
    "labels_train = newLabels[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "newXtest = []\n",
    "for x in pixel_array_test:\n",
    "    xx = np.empty([x.shape[0], x.shape[1], 3], dtype=np.float32)\n",
    "    xx[:,:,0] = x[:,:,0]\n",
    "    xx[:,:,1] = x[:,:,0]\n",
    "    xx[:,:,2] = x[:,:,0]\n",
    "    newXtest.append(xx)\n",
    "\n",
    "newXtest = np.asarray(newXtest)\n",
    "\n",
    "newXtrain = []\n",
    "for x in pixel_array_train:\n",
    "    xx = np.empty([x.shape[0], x.shape[1], 3], dtype=np.float32)\n",
    "    xx[:,:,0] = x[:,:,0]\n",
    "    xx[:,:,1] = x[:,:,0]\n",
    "    xx[:,:,2] = x[:,:,0]\n",
    "    newXtrain.append(xx)\n",
    "\n",
    "newXtrain = np.asarray(newXtrain)\n",
    "\n",
    "newXtarget = []\n",
    "for x in pixel_array_val:\n",
    "    xx = np.empty([x.shape[0], x.shape[1], 3], dtype=np.float32)\n",
    "    xx[:,:,0] = x[:,:,0]\n",
    "    xx[:,:,1] = x[:,:,0]\n",
    "    xx[:,:,2] = x[:,:,0]\n",
    "    newXtarget.append(xx)\n",
    "    \n",
    "newXtarget = np.asarray(newXtarget)\n",
    "\n",
    "print(newXtrain.shape, labels_train.shape)\n",
    "print(newXtarget.shape, labels_val.shape)\n",
    "print(newXtest.shape, labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(newXtrain[0]), np.max(newXtrain[0]))\n",
    "print(np.min(newXtrain[1]), np.max(newXtrain[1]))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(labels_train[0])\n",
    "plt.imshow(newXtrain[0], cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(labels_train[1])\n",
    "plt.imshow(newXtrain[1], cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "model_path_pretrained = \"/Shared/CipacProcessing/Projects/RF_ML_ENA1/05-Scripts/RadImageNet-ResNet50_notop.h5\"\n",
    "\n",
    "pretrained_model = tf.keras.applications.ResNet50(include_top=False,\n",
    "                        input_shape=None,\n",
    "                        pooling='avg',\n",
    "                        weights=model_path_pretrained)\n",
    "\n",
    "pretrained_model.trainable = False\n",
    "# added new:\n",
    "# fine_tune_at = len(pretrained_model.layers) // 2\n",
    "# for layer in pretrained_model.layers[:fine_tune_at]:\n",
    "#     layer.trainable = False\n",
    "\n",
    "input_A = keras.layers.Input(shape=[1024, 1024, 3]) # maybe change to 1024, 1024, 1\n",
    "input_A = preprocess_input(input_A)\n",
    "\n",
    "fc = keras.layers.Flatten()(pretrained_model(input_A, training=False))\n",
    "fc = tf.keras.layers.Dropout(0.5)(fc)\n",
    "fc = keras.layers.Dense(30, activation=tf.keras.layers.LeakyReLU(0.1))(fc)\n",
    "fc = tf.keras.layers.Dropout(0.4)(fc)\n",
    "fc = keras.layers.Dense(1, activation=\"sigmoid\")(fc)\n",
    "\n",
    "# fc = keras.layers.Flatten()(pretrained_model(input_A, training=False))\n",
    "# fc = tf.keras.layers.Dropout(0.5)(fc)\n",
    "# fc = keras.layers.Dense(100, activation=tf.keras.layers.LeakyReLU(0.3), kernel_regularizer=regularizers.l2(0.001))(fc)\n",
    "# fc = tf.keras.layers.Dropout(0.3)(fc)\n",
    "# fc = keras.layers.Dense(1, activation=\"sigmoid\")(fc)\n",
    "\n",
    "model = keras.Model(inputs=[input_A], outputs=[fc])\n",
    "\n",
    "\n",
    "opt = legacy.Adam(learning_rate=1e-4, decay=1e-7)\n",
    "\n",
    "# Define the callbacks\n",
    "#earlyStopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='auto')\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-8)\n",
    "\n",
    "model_chck_point_path = \"/Shared/CipacProcessing/Projects/RF_ML_ENA1/mymodel_capstone.h5\"\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(model_chck_point_path, mode = 'auto', monitor='val_loss',verbose=0, save_best_only=True)\n",
    "\n",
    "# Compile the model with the optimizer\n",
    "model.compile(loss=[tf.keras.losses.BinaryCrossentropy(label_smoothing=0.1)], optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input\n",
    "\n",
    "datagen_test = ImageDataGenerator(\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = datagen_train.flow(newXtrain[:2], labels_train[:2],batch_size=2)\n",
    "count = 0\n",
    "for img,label in data_:\n",
    "    print(img.shape)\n",
    "    plt.figure()\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title(label[0])\n",
    "    plt.imshow(img[0], cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title(label[1])\n",
    "    plt.imshow(img[1], cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    count += 1\n",
    "\n",
    "    if count == 10:\n",
    "        break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size_ = 2\n",
    "# hist = model.fit(datagen_train.flow(pixel_array_train[:2], labels_train[:2],batch_size=batch_size_, shuffle=True), \n",
    "#                  steps_per_epoch=math.ceil(len(pixel_array_train[:2]) / batch_size_),\n",
    "#                  epochs=25, \n",
    "#                  verbose = 1, \n",
    "#                  validation_data = datagen_test.flow(pixel_array_val[:2], labels_val[:2],batch_size=2),\n",
    "#                  callbacks = [checkpoint, reduce_lr])\n",
    "\n",
    "\n",
    "batch_size_ = 20\n",
    "hist = model.fit(datagen_train.flow(newXtrain, labels_train,batch_size=batch_size_, shuffle=True), \n",
    "                 steps_per_epoch=math.ceil(len(newXtrain) / batch_size_),\n",
    "                 epochs=10, \n",
    "                 verbose = 1, \n",
    "                 validation_data = datagen_test.flow(newXtarget, labels_val,batch_size=24),\n",
    "                 callbacks = [checkpoint, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,5), dpi=150)\n",
    "plt.grid('on')\n",
    "plt.title('Loss Function')\n",
    "plt.plot(hist.history['loss'], 'b', lw=2, alpha=0.7, label='Training')\n",
    "plt.plot(hist.history['val_loss'], 'r', lw=2, alpha=0.7, label='Val')\n",
    "plt.legend(loc=\"upper right\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('envTF')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0c9ed33df72587aa5d903227ad7b6811fb64f7ecd706c1767190268c3eb24d34"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
